{
  "metadata" : {
    "kernelspec" : {
      "display_name" : "Python 2",
      "language" : "python",
      "name" : "python2"
    },
    "language_info" : {
      "file_extension" : ".py",
      "mimetype" : "text/x-python",
      "name" : "python"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 2,
  "cells" : [ {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "# Week 1\r\n\r\nThis week we will investigate ML basics and a variety of ML techniques use as they are implemented in scikit-learn.  Throughout the rest of the class we will be working with our final project dataset on every assignment to see how to bring to bear the tools and techniques covered in that week apply to a specific ML problem, however on this one we will experiment a bit with a built in dataset in scikit-learn.  Scikit-learn has [a plethora of small datasets to play with](http://scikit-learn.org/stable/datasets/index.html), and we'll be making use of the digit recognition dataset.\r\n\r\n## Goals\r\n* Re-familiarize ourselves with Eider, and learn about Scikit-learn.\r\n* Experiment with a couple of black-box ML techniques from Scikit-learn\r\n* See the difference between supervised and unsupervised learning\r\n\r\n## Resources\r\nHere are a some resources that might be of interest while working on this assignment.  It includes relevant chapters of our book and all libraries you might wish to use during this, and all later, lectures.  Of particular note is [Eider Expo](https://eider.corp.amazon.com/expo) which lets you search for notebooks that demonstrate particular libraries or concepts.\r\n\r\n* *Python Machine Learning*\r\n    * Chapter 1: all pages\r\n    * Chapter 3: all pages exclude perceptron related\r\n    * Chapter 10: page 277-290, 294-296\r\n    * Chapter 11: page 311-317, 320-321\r\n* Scikit-learn\r\n    * [Quick-Start tutorial](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\r\n    * [User Guide](http://scikit-learn.org/stable/user_guide.html)\r\n    * [Chosing the right estimator](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\r\n    * [API](http://scikit-learn.org/stable/modules/classes.html)\r\n* Pandas\r\n    * [API](http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html)\r\n    * [Visualization](http://pandas.pydata.org/pandas-docs/version/0.18.1/visualization.html)\r\n* matplotlib\r\n    * [Plotting API](http://matplotlib.org/api/pyplot_summary.html)\r\n    * [Gallery](http://matplotlib.org/gallery.html)\r\n* NumPy\r\n    * [API](https://docs.scipy.org/doc/numpy/reference/routines.html)\r\n* Eider\r\n    * [User guide documentation](https://w.amazon.com/index.php/Eider/Documentation)\r\n    * [Expo](https://eider.corp.amazon.com/expo)" ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "## Question 1\n\nLoad in the [handwritten digits dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-data-set) using [load_digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits).  This is the dataset we will be working with today.  Use [matplotlib]()'s ```imshow``` to take a look at the first 10 elements of this dataset to see what we are dealing with (don't forget to reshape them back into images)." ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from sklearn.datasets import load_digits\ndigits = load_digits()\nimport matplotlib.pyplot as plt \nimport pylab as pl\n\nplt.gray()\n\ndef show_pictures(data, labels=None,fig_title=None):\n    num = len(data)\n    fig, ax = plt.subplots(1, num, figsize=(14, 2.1))\n    if fig_title:\n        fig.suptitle(fig_title)\n    for k in range(num):\n        ax[k].imshow(data[k].reshape((8,8)))\n        if labels is not None:\n            ax[k].set_title(\"This is: \" + str(labels[k]))\nshow_pictures(digits.data[:10], labels=digits.target[:10], fig_title=\"First 10 digits from the sample set of %d with target label\" % len(digits.data))" ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "We will first experiment with the dataset as an unsupervised learning problem---that is ignoring the class labels that we were provided.  In particular, we will investigate attempting to cluster these digits using $K$-means.  We know that there are 10 classes to work with, so we will start with $K=10$.\n\n## Question 2\nImplement $K$-means clustering on the digits dataset with $K=10$ using [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).  The cluster centers are an average of all examples assigned to that cluster, and so can be thought of as the prototypical behavior of the digits in that cluster.  The output from this routine is somewhat stochastic, so try running it a couple of times and explain below what you see.  Are there cluster centers clearly for all $10$ digit classes?  How about what happens if you have the number of cluster centers wrong: say 4 or 12?  Please be critical of these algorithms as it is often tempting to see the power and turn a blind eye to their failings." ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\ndef run_kmeans(clusters, rs=0):\n    return KMeans(n_clusters=clusters, init='random', random_state=rs).fit(digits.data)\n\ndef kmeans_with_pictures(clusters, rs=0):\n    kmeans = run_kmeans(clusters, rs=rs)\n    show_pictures(sorted(kmeans.cluster_centers_, key=sum), fig_title=\"Sorted centers for %d clusters random seed: %d\" % (clusters, rs))\n    return kmeans\n\nkmeans = kmeans_with_pictures(10,0)\n\n# The seeds are arbitrarily selected.\n# We explicitly select seeds to have a predictable output that matches our observations in the discussion.\nkmeans_with_pictures(10, 65439793)\nkmeans_with_pictures(10, 768827)\nkmeans_with_pictures(4, 12396)\nkmeans_with_pictures(12, 96234012)" ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "## Discussion for Question 2\n\nThe cluster centers for Kmeans-10 look pretty close to the numbers themselves. Reruning the KMeans with different random settings also yieldst to very similar clusters, however sometimes it can have big differences.\n\nWith KMeans - 4, the clusters are getting much blurier. Number 9 still stands out, but other clusters look like several numbers melted together.\n\nWith KMeans - 12, the clusters can be more 'precise' and more centers can isolate the same number. The number 8 center became more clear, and we have two centers for number 7 and probably also for number 1." ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "## Question 3\nTo be rigorous about the performance of the model, you can take the labels associated to each digit and see if they are all associated to the same cluster.  Use the ```predict``` function associated with ```KMeans``` to predict which class center each digit was clustered with.  Is there any particular digit which gets spread out over many clusters?" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def run_cluster_stats(digits, algorithm):\n    num_samples = len(digits.data)\n    prediction = [algorithm.predict(digits.data[x].reshape(1,-1))[0] for x in xrange(num_samples)]\n    x = pd.DataFrame({ 'target': digits.target, 'cluster' : prediction, 'match_count' : np.ones(num_samples) })\n    target_count = x[['target','match_count']].groupby('target',as_index=False).count()\n    cluster_count = x[['cluster','match_count']].groupby('cluster',as_index=False).count()\n    g = x.groupby(by=['target','cluster'],as_index=False).count()\n    g = g.merge(target_count,on=['target'], suffixes=['','_target'])\n    g = g.merge(cluster_count,on=['cluster'], suffixes=['','_cluster'])\n    g.rename(columns={'match_count_target': 'target_count', 'match_count_cluster': 'cluster_count'}, inplace=True)\n    g['pct_target'] = (g['match_count']/g['target_count'])*100.0\n    g['pct_cluster'] = (g['match_count']/g['cluster_count'])*100.0\n    return g\n    \ng = run_cluster_stats(digits, kmeans)\ndef print_cluster_stats_help():\n    print \"match_count - number of target-cluster pairs\"\n    print \"target_count - number of target values\"\n    print \"cluster_count - number of cluster values\"\n    print \"pct_target - how many targets does this target-cluster pair covers?\"\n    print \"pct_cluster - how big percentage from the cluster is the current target-cluster pair?\\n\\n\"\nprint_cluster_stats_help()\ng[g['pct_cluster'] > 40].sort_values(['target'],ascending=False)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def run_error_rate(clusters):\n    kmeans = run_kmeans(clusters)\n    g = run_cluster_stats(digits, kmeans)\n    c_max = g[['cluster','pct_cluster']].groupby(['cluster'],as_index=False).max()\n    g_max = g.merge(c_max, on=['cluster'], suffixes=['','_max'])\n    g_max = g_max[g_max['pct_cluster'] == g_max['pct_cluster_max']]\n    return (g_max['cluster_count'] - g_max['match_count']).sum()\nn_clusters = range(2,50,2)\nvalues = [run_error_rate(x) for x in n_clusters]\nplt.scatter(n_clusters, values)" ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "## Discussion for Question 3\n\nWe run a simple error summary comparing how well the clusters cover their target in respect to a single target digit. As you can see from the graph, the error starts pretty big, which make sense with few cluster, and starts to be narrow at around 12 clusters, which might indicate, that the 12 clusters are first good approximation of the clusters." ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "As you undoubtedly see it does an impressive, albeit flawed, job of separating the digits into their natural classes completely without labeled data.  Often times, certain similar classes blur together, and some classes may be missing a definitive class at all, and some classes that have high diversity may split into many.\n\nThis is not particularly surprising.  We basically just told the algorithm, \"Here is a pile of vectors without context, what do you see?\"  Sometimes we need to do that if there are no labels available to us, however here we discarded the labels we were given.  Let's now try to now fit a supervised model: a version of logistic regression made for multiple classes.\n\n## Question 4\nImplement [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to try to predict digit labels.  Much like the cluster centers from before, each class has an associated weight vector what is used specify the class, so please plot those to see how the class decision is being made.  Can you identify the digit classes now from the weights?" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nmodel = lr.fit(digits.data, digits.target)\nshow_pictures(model.coef_, fig_title=\"Coefficients of logistic regression\")" ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "## Discussion for Question 4\n\nNo, the weight vectors don't look anything like numbers. They look more as a random images." ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "You most likely saw that the weights learned from the logistic regression look essentially like noise with only the slightest hints of the digits.  We do not dig into this in this assignment, but this noisy appearance is partially due to overfitting, where the model weights heavily random fluctuation that happens to be indicative of class label in our dataset.\n\nHowever, now, we will see that our model does a much better job of classifying the digits it trained on.\n\n## Question 5\nAs in **Question 3**, you can now take the labels predicted for each digit and see if they are all the ones they trained on.  Is there any particular digit which gets spread out over many clusters now?" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "print_cluster_stats_help()\nrun_cluster_stats(digits, lr)" ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "## Discussion for Question 5\n\nThe clusters are much more precise. Some of the clusters have 100% coverage, meaning they cover only one exact number. Number 9, 1 and 8 also occure in different clusters, but with low percentage. The highest is 8, which is in cluster for number 1 with 2.7% of cases." ]
  }, {
    "cell_type" : "markdown",
    "metadata" : { },
    "source" : [ "You will have likely seen that it does an almost perfect job.  We don't investigate further here, but don't be fooled by this behavior!  As hinted at before, this model is overfitting severely, and if we had set aside some of the digits at the beginning of this notebook to test on later, we would see it does not do such a good job with previously unseen digits.  Being careful about this, however, is a topic for a later lecture." ]
  } ]
}